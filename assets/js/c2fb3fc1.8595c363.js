"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[517],{3905:function(e,t,a){a.d(t,{Zo:function(){return l},kt:function(){return f}});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var p=n.createContext({}),c=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},l=function(e){var t=c(e.components);return n.createElement(p.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,p=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),d=c(a),f=r,g=d["".concat(p,".").concat(f)]||d[f]||u[f]||i;return a?n.createElement(g,o(o({ref:t},l),{},{components:a})):n.createElement(g,o({ref:t},l))}));function f(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=d;var s={};for(var p in t)hasOwnProperty.call(t,p)&&(s[p]=t[p]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var c=2;c<i;c++)o[c]=a[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},1781:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return s},contentTitle:function(){return p},metadata:function(){return c},toc:function(){return l},default:function(){return d}});var n=a(7462),r=a(3366),i=(a(7294),a(3905)),o=["components"],s={},p="Process Your Own Data",c={unversionedId:"WebUI/use_data_operations_to_process_your_data",id:"WebUI/use_data_operations_to_process_your_data",title:"Process Your Own Data",description:"Another key feature of DataLab is the standardization of different data operations into a unified",source:"@site/docs/WebUI/8_use_data_operations_to_process_your_data.md",sourceDirName:"WebUI",slug:"/WebUI/use_data_operations_to_process_your_data",permalink:"/DataLab/docs/WebUI/use_data_operations_to_process_your_data",editUrl:"https://github.com/ExpressAI/DataLab/tree/gh-pages/docs/WebUI/8_use_data_operations_to_process_your_data.md",tags:[],version:"current",sidebarPosition:8,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Dataset Recommendation",permalink:"/DataLab/docs/WebUI/dataset_recommendation_based_on_idea"},next:{title:"Analyzing Summarization Datasets",permalink:"/DataLab/docs/WebUI/analyzing_summarization_datasets"}},l=[{value:"Preprocessing",id:"preprocessing",children:[],level:3},{value:"Editing (Transformation)",id:"editing-transformation",children:[],level:3},{value:"Featurizing",id:"featurizing",children:[],level:3},{value:"Aggregating",id:"aggregating",children:[],level:3},{value:"Prompting",id:"prompting",children:[],level:3}],u={toc:l};function d(e){var t=e.components,a=(0,r.Z)(e,o);return(0,i.kt)("wrapper",(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"process-your-own-data"},"Process Your Own Data"),(0,i.kt)("p",null,"Another key feature of DataLab is the standardization of different data operations into a unified\nformat to satisfy different data processing requirements in one place.\nTo this end, we devised a general typology for the concepts of data and operation as shown below and curated schemas for these objects."),(0,i.kt)("img",{src:"https://user-images.githubusercontent.com/59123869/155357470-8b95671c-d5e4-45bb-9edf-076d33c1e6f2.png",width:"600"}),(0,i.kt)("p",null,"Specifically, using ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/ExpressAI/DataLab"},"DataLab SDK"),", you can conveniently "),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"process data with a unified interface"),(0,i.kt)("li",{parentName:"ul"},"and use rich operations supported by SDK by passing different operation names")),(0,i.kt)("img",{src:"https://user-images.githubusercontent.com/59123869/155447749-457820f2-d0e5-4426-acb2-17ea3bdff011.png",width:"600"}),(0,i.kt)("p",null,"You can install the SDK by:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"pip install --upgrade pip\npip install datalabs\n")),(0,i.kt)("p",null,"So far, DataLab supports following types of data operations and implements some functions for each operation. Users can continue expanding\nthem by yourselves."),(0,i.kt)("h3",{id:"preprocessing"},"Preprocessing"),(0,i.kt)("p",null,"Data preprocessing (e.g., tokenization) is an indispensable step in training deep  learning and machine learning models,\nand the quality of the dataset directly affects the learning of models. Currently, DATALAB supports both general preprocessing functions\nand task-specific ones, which are built based on different sources, such as Spacy, NLTK and Huggingface."),(0,i.kt)("img",{src:"https://user-images.githubusercontent.com/59123869/155447787-063de6fa-f6aa-4377-88d2-f985d5ff080c.png",width:"600"}),(0,i.kt)("h3",{id:"editing-transformation"},"Editing (Transformation)"),(0,i.kt)("p",null,"Editing aims to apply certain transformations to a given text, which spans multiple important applications in NLP,\nfor example "),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"adversarial evaluation ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2005.04118.pdf"},"(Ribeiro et al., 2021)"),", which usually requires diverse perturbations on test samples to test the robustness of a system."),(0,i.kt)("li",{parentName:"ul"},"data augmentation ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2112.02721.pdf"},"(Dhole et al., 2021)"),".\nEssentially, many of the methods for constructing augmented or diagnostic datasets involve some editing operation on the original dataset\n(e.g., named entity replacement in diagnostic dataset construction ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2005.04118.pdf"},"(Ribeiro et al., 2021)"),", token deletion in data augmentation ",(0,i.kt)("a",{parentName:"li",href:"https://aclanthology.org/D19-1670.pdf"},"jason_2019"),".\nDataLab provides a unified interface for data editing and users can easily apply to edit the data they are interested in.")),(0,i.kt)("img",{src:"https://user-images.githubusercontent.com/59123869/155447848-794b6f94-e280-4874-953c-b7cfd02b2d65.png",width:"600"}),(0,i.kt)("h3",{id:"featurizing"},"Featurizing"),(0,i.kt)("p",null,"This operation aims to compute sample-level features of a given text.\nIn DataLab, in addition to designing some general feature functions (e.g. ",(0,i.kt)("inlineCode",{parentName:"p"},"*get_length()*")," operation\ncalculates the length of the text.), we also customize some feature functions for specific tasks (e.g. ",(0,i.kt)("inlineCode",{parentName:"p"},"*get_oracle()*"),"\noperation for the summarization task that calculates the oracle summary of the source text.)."),(0,i.kt)("img",{src:"https://user-images.githubusercontent.com/59123869/155447958-74deb639-8ff1-49cf-88fa-fa82439cc68c.png",width:"600"}),(0,i.kt)("h3",{id:"aggregating"},"Aggregating"),(0,i.kt)("p",null,"Aggregation operations are used to compute corpus-level statistics such as TF-IDF,\nlabel distribution. Currently, DataLab supports both generic aggregation operations applicable to any task and some customized ones\nfor four NLP tasks (classification, summarization, extractive question answering and natural language inference)."),(0,i.kt)("h3",{id:"prompting"},"Prompting"),(0,i.kt)("p",null,"Prompt-based learning ",(0,i.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/2107.13586.pdf"},"Liu et al. 2021")," has received considerable attention, as better utilization of pretrained\nlanguage models benefits many NLP tasks.\nSo far, DataLab includes different prompt templates  which can be applied to five types of tasks\n(topic classification, sentiment classification, sentence entailment,\nsummarization, natural language inference)."))}d.isMDXComponent=!0}}]);